{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description: \n",
    "\n",
    "Description: In this notebook, we read all the information available from different datasets and we preprocess this information in order to create the categories that will be feed to the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages necessary to make connection with azure data lake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#import libraries to create connection\n",
    "from azure.datalake.store import core, lib, multithread\n",
    "from azure.common.credentials import ServicePrincipalCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get authentification for the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from azure.common.credentials import ServicePrincipalCredentials\n",
    "token1 = lib.auth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T05:20:44.558802Z",
     "start_time": "2020-07-13T05:20:44.282669Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy\n",
    "\n",
    "year = '2015'\n",
    "\n",
    "#define paths\n",
    "path_local = '/Users/mendes/Box Sync/ABI-Project/Project'\n",
    "path_inbound = path_local+f'/NAZ/People/TurnoverModel/Data/Inbound/{year}/'\n",
    "path_working = path_local+f'/NAZ/People/TurnoverModel/Data/Working/{year}/'\n",
    "\n",
    "#define paths to read the inputs and save outputs\n",
    "path_head = path_inbound+'02 SharpOps/head/'\n",
    "path_movements = path_inbound+'02 SharpOps/movements/'\n",
    "path_sharps = path_inbound+'02 SharpOps/'\n",
    "path_navigate = path_inbound+'04 Navigate/'\n",
    "path_bonus = path_inbound+'01 Bonus and Salary/'\n",
    "\n",
    "path_to_save = '/Users/mendes/tech_interview/ABI-tech/Input/SharpOps/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T12:40:47.733903Z",
     "start_time": "2020-07-15T12:40:47.652007Z"
    },
    "code_folding": [
     0,
     11,
     23,
     42,
     180,
     401,
     426,
     441,
     454
    ]
   },
   "outputs": [],
   "source": [
    "def adlsopen(x):\n",
    "    \"\"\"\n",
    "    A decorator function to open a file using the azure services in datalake.\n",
    "    \n",
    "    Args:\n",
    "        x: filepath to open\n",
    "    Returns:\n",
    "        x: the filepath in the datalake\n",
    "    \"\"\"\n",
    "    return x\n",
    "\n",
    "def save_csv_adls(df,path,adls=False):\n",
    "    \"\"\"\n",
    "    A decorator function to save a pandas dataframe using the azure services in datalake.\n",
    "    \n",
    "    Args:\n",
    "        df (Pandas DataFrame): dataframe to save\n",
    "        path (String): string with the filepath to save the file\n",
    "    \"\"\"\n",
    "    df.to_csv(path,index=False)\n",
    "\n",
    "adls=False\n",
    "\n",
    "def convert_id(col):\n",
    "    \"\"\"\n",
    "    Convert ids with mismatches or missing initial numbers from headcounts\n",
    "    \n",
    "    Args:\n",
    "        col (Pandas Series): pandas series containing the ids\n",
    "    Returns:\n",
    "        l (list): list with the fixed ids\n",
    "    \"\"\"\n",
    "    l=[]\n",
    "    for k in col:\n",
    "        k=str(k)\n",
    "        if len(k)==4: k='1000'+k\n",
    "        elif len(k)==5: k='100'+k\n",
    "        elif len(k)==6: k='10'+k\n",
    "        elif len(k)==7: k='1'+k\n",
    "        l.append(k)\n",
    "    return l\n",
    "\n",
    "def headcount_procedure(hdf,idx_left=None,fixYear=True):\n",
    "    \"\"\"\n",
    "    Convert the raw dataset for headcount into a processed dataset to be inserted in the model\n",
    "    \n",
    "    Args:\n",
    "        hdf (Pandas DataFrame): raw headcount dataset\n",
    "        idx_left (Pandas Series) = indexes for people who left the company\n",
    "    Returns:\n",
    "        hdf (Pandas DataFrame): pandas dataframe with headcount dataset processed\n",
    "    \"\"\"\n",
    "    #remove columns that don't have important information or are already represented by others\n",
    "    cols_remove = ['Original Hire Date', 'Rehire Date','New Hire', 'Personnel number', 'Full Name',\n",
    "               'Position','CostCenter Description','ABInbev Entity1',\n",
    "               'ABInbev Entity3', 'ABInbev Entity4','Company Code','Personnel area',\n",
    "               'Personnel subarea','Employee subgroup','Short Text of Organizational Unit','Gender', 'Ethnicity',\n",
    "               'Personnel Area Text','Functional Area','Manager Position','Cost Center']\n",
    "    hdf=hdf.drop(cols_remove,axis=1)\n",
    "\n",
    "    #remove special characters and transform all to lower case\n",
    "    hdf.columns = replace_special(list(hdf.columns))\n",
    "\n",
    "    #remove duplicated rows from the dataframe\n",
    "    hdf=hdf[~hdf.duplicated('global id')]\n",
    "\n",
    "    #calculate age fom date of birth\n",
    "    hdf['age'] = get_age_from_birth(hdf['date of birth'],fixYear=fixYear)\n",
    "    hdf = hdf.drop(['date of birth'],axis=1)\n",
    "\n",
    "    #transform age information into percentiles\n",
    "    hdf['age compared'] = get_stds(hdf['age']) \n",
    "\n",
    "    #transform the age information into buckets with 5 years\n",
    "    hdf['age buckets'] = pd.cut(hdf['age'],bins=range(0,100,5),include_lowest=True).astype(str)\n",
    "    hdf=hdf.drop(['age'],axis=1)\n",
    "\n",
    "    #calculate the service year anniversaries based on the service year metric\n",
    "    for num in [1,2,3,5,10,20]:\n",
    "        hdf[str(num) + ' - anniversary'] = (hdf['service years']>=num).astype(float)\n",
    "\n",
    "    #transform service years information into percentiles\n",
    "    hdf['service years compared'] = get_stds(hdf['service years']) \n",
    "\n",
    "    #transform the service years information into buckets with 5 years\n",
    "    hdf['service years buckets'] = pd.cut(hdf['service years'],bins=range(0,100,5),include_lowest=True).astype(str)\n",
    "\n",
    "    #convert the global id for the manager to the defined standard \n",
    "    hdf['personnel number manager'] = convert_id(hdf['personnel number manager'])\n",
    "\n",
    "    #add information about pay scale and service years for the manager\n",
    "\n",
    "    ##make a copy of the original dataframe\n",
    "    aux=hdf.copy(deep=True)\n",
    "    l=[]\n",
    "\n",
    "    ##get a list of all the possible global ids\n",
    "    gid = list(aux['global id'].astype(str))\n",
    "\n",
    "    ##loop through all the ids contained in the personal manager column\n",
    "    for k in aux['personnel number manager'].values:\n",
    "        try:\n",
    "            ###check if the global id for the manager is in the general list of global ids and return the index\n",
    "            idx = gid.index(str(k))\n",
    "            a=idx\n",
    "        except Exception as e:\n",
    "            ###if the manager global id is not present, just return None\n",
    "            a=None\n",
    "        l.append(a)\n",
    "\n",
    "    ##create a new series that contain the indexes for the manager global ids that are presented in the original one\n",
    "    l=pd.Series(l)\n",
    "\n",
    "# \t##slice the dataframe to retrive the important information\n",
    "# \taux=aux.iloc[l,['service years','pay scale group']]\n",
    "    aux=aux.reindex(index=l)[['service years','pay scale group']]\n",
    "\n",
    "    ##identify which columns belong to the managers\n",
    "    aux.columns = ['manager - '+k for k in aux.columns]\n",
    "\n",
    "    ##add the original employee global id information in order to perform the join operation\n",
    "    aux['global id']=hdf['global id'].values\n",
    "\n",
    "    ##add the manager calculated information to the main dataframe\n",
    "    hdf=hdf.join(aux.set_index('global id'),on='global id')\n",
    "\n",
    "    #calculate the gap difference between employee pay scale group and manager pay scale group\n",
    "\n",
    "    ##slice the dataframe to retrieve the information about pay scale group\n",
    "    aux = hdf[['pay scale group','manager - pay scale group']].copy(deep=True)\n",
    "\n",
    "    ##iterate over each one of the columns in the sliced dataframe\n",
    "    for col in aux.columns:\n",
    "        ###preprocess the information in each element of the pay scale group\n",
    "        aux[col+' numerical'] = [k.strip().lower().replace(' ','-').replace('--','-').replace('us-','') if k is not numpy.nan else k for k in aux[col]]\n",
    "\n",
    "        ###convert each value in pay scale group to a numerical band\n",
    "        aux[col+' numerical'] = [band_dict[k] if k is not numpy.nan else k for k in aux[col+' numerical']]\n",
    "\n",
    "    ##calculate the gap in band using the information calculated from pay scale group\n",
    "    aux['delta band with manager'] = aux['pay scale group numerical']  - aux['manager - pay scale group numerical']\n",
    "\n",
    "    l=[]\n",
    "    ##convert the delta to defined buckets in order to categorize the information\n",
    "    for val in aux['delta band with manager']:\n",
    "        if val<-4:\n",
    "            a='bigger than -4'\n",
    "        elif val<-2:\n",
    "            a='between -4 and -2'\n",
    "        elif val<0:\n",
    "            a='between -2 and 0'\n",
    "        elif val<2:\n",
    "            a='between 0 and 2'\n",
    "        elif val<=4:\n",
    "            a='between 2 and 4'\n",
    "        elif val>4:\n",
    "            a='bigger than 4'\n",
    "        l.append(a)\n",
    "\n",
    "    ##create a new column with the information about gap converted in ordinal categories\n",
    "    aux['delta band with manager categorized'] = l\n",
    "\n",
    "    ##copy the calculated information into the original dataframe\n",
    "    hdf['delta band with manager'] = aux['delta band with manager'].values\n",
    "\n",
    "    #add the information about the label\n",
    "    if idx_left:\n",
    "        ##initiate the label column\n",
    "        hdf['label'] = 0\n",
    "\n",
    "        ##update the labels for the people who were not in the company\n",
    "        hdf = hdf.set_index('global id')\n",
    "\n",
    "        ##assign 1 for people who left the company and reset index\n",
    "        hdf.reindex(idx_left)[['label']] = 1\n",
    "        hdf = hdf.reset_index()\n",
    "\n",
    "    hdf['global id'] = hdf['global id'].astype(float).astype(int).astype(str)\n",
    "    return hdf\n",
    "\n",
    "def replace_special(element,enconding=None,verbose=False):\n",
    "    \"\"\"\n",
    "    Fix problems realted to encoding caused by characters with incorrect encoding type.\n",
    "    \n",
    "    Args:\n",
    "        element (unicode, list or Pandas Dataframe'): The element to be fixed. \n",
    "        It can be a single unicode element or \n",
    "        an entire pandas DataFrame where each element will be fixed\n",
    "    Returns:\n",
    "        element (unicode, list or Pandas Dataframe'): The fixed element\n",
    "    \"\"\"\n",
    "\n",
    "    def replace_str(text):\n",
    "        if pd.isnull(text):\n",
    "            return None\n",
    "        #if '?' in text: text = text.replace('?',' ')\n",
    "        try:\n",
    "            str(text)\n",
    "            text.encode('utf-8')\n",
    "            text = text.lower()\n",
    "        except:\n",
    "            try:\n",
    "                text=str(text)\n",
    "            except:\n",
    "                if verbose:\n",
    "                    print(text)\n",
    "                return \"codec error\"\n",
    "            text = text.lower()\n",
    "\n",
    "            if '\\xcc\\xe4' in text: text = text.replace('\\xcc\\xe4','e')\n",
    "            if '\\x87\\xc6' in text: text = text.replace('\\x87\\xc6','ca')\n",
    "            if '\\x8d\\x86' in text: text = text.replace('\\x8d\\x86','ca')\n",
    "            if '\\x8d\\x8b' in text: text = text.replace('\\x8d\\x8b','ca')\n",
    "            if '\\x8d\\x9b' in text: text = text.replace('\\x8d\\x8b','co')\n",
    "            if '\\xe7\\xe3' in text: text = text.replace('\\xe7\\xe3','ca')\n",
    "            if '\\x87\\xc6' in text: text = text.replace('\\x87\\xc6','ca')\n",
    "            if '\\x87\\xe4' in text: text = text.replace('\\x87\\xe4','co')\n",
    "\n",
    "            if 'ri\\x88' in text: text = text.replace('ri\\x88','rie')\n",
    "            if '\\xb5re' in text: text = text.replace('\\xb5re','are')\n",
    "            if '\\xa3de' in text: text = text.replace('\\xa3de','ude')\n",
    "            if '\\xa1st' in text: text = text.replace('\\xa1st','ist')\n",
    "            if '\\xa1di' in text: text = text.replace('\\xa1di','idi')\n",
    "            if '\\x88nc' in text: text = text.replace('\\x88nc','enc')\n",
    "            if '\\xa2lo' in text: text = text.replace('\\xa2lo','olo')\n",
    "            if '\\xa3bl' in text: text = text.replace('\\xa3bl','ubl')\n",
    "            if '\\xa1si' in text: text = text.replace('\\xa1si','isi')\n",
    "            if '\\xa1mi' in text: text = text.replace('\\xa1mi','imi')\n",
    "            if '\\xa1de' in text: text = text.replace('\\xa1de','ide')\n",
    "            if '\\xc4a' in text: text = text.replace('\\xc4a','a')\n",
    "\n",
    "\n",
    "            if enconding!=None:\n",
    "                if '\\xa1' in text: text = text.replace('\\xa1','i')\n",
    "                if '\\xa2' in text: text = text.replace('\\xa2','o')\n",
    "\n",
    "\n",
    "            if '\\xb1' in text: text = text.replace('\\xb1','n')\n",
    "            if '\\xf0' in text: text = text.replace('\\xf0','-')\n",
    "            if '\\x98' in text: text = text.replace('\\x98','-')\n",
    "            if '\\xff' in text: text = text.replace('\\xff','-')\n",
    "            if '\\xa6' in text: text = text.replace('\\xa6','-')\n",
    "            if '\\xbd' in text: text = text.replace('\\xbd','-')\n",
    "            if '\\x8c' in text: text = text.replace('\\x8c','i')\n",
    "            if '\\xc3' in text: text = text.replace('\\xc3','')\n",
    "            if '\\x8d\\x8bo' in text: text = text.replace('\\x8d\\x8bo','cao')\n",
    "            if '\\xca' in text: text = text.replace('\\xca','e')\n",
    "            if '\\x90' in text: text = text.replace('\\x90','e')\n",
    "            if '\\x92' in text: text = text.replace('\\x92','i')\n",
    "            if '\\x97' in text: text = text.replace('\\x97','o')\n",
    "            if '\\x87' in text: text = text.replace('\\x87','a')\n",
    "            if '\\xee' in text: text = text.replace('\\xee','o')\n",
    "            if '\\xd4' in text: text = text.replace('\\xd4','o')\n",
    "\n",
    "            if '\\xec' in text: text = text.replace('\\xec','u')\n",
    "            if '\\x86' in text: text = text.replace('\\x86','a')\n",
    "            if '\\x88' in text: text = text.replace('\\x88','a')\n",
    "            if '\\x84' in text: text = text.replace('\\x84','o')\n",
    "            if '\\xed' in text: text = text.replace('\\xed','i')\n",
    "            if '\\xf3' in text: text = text.replace('\\xf3','o')\n",
    "            if '\\xe1' in text: text = text.replace('\\xe1','a')\n",
    "            if '\\xf5' in text: text = text.replace('\\xf5','o')\n",
    "            if '\\xe9' in text: text = text.replace('\\xe9','e')\n",
    "            if '\\xea' in text: text = text.replace('\\xea','e')\n",
    "            if '\\xf6' in text: text = text.replace('\\xf6','e')\n",
    "            if '\\xe4' in text: text = text.replace('\\xe4','e')\n",
    "            if '\\xe8' in text: text = text.replace('\\xe8','e')\n",
    "\n",
    "            if '\\xa0' in text: text = text.replace('\\xa0','a')\n",
    "            if '\\xa1' in text: text = text.replace('\\xa1','a')\n",
    "            if '\\xc1' in text: text = text.replace('\\xc1','a')\n",
    "            if '\\xa2' in text: text = text.replace('\\xa2','a')\n",
    "            if '\\xa3' in text: text = text.replace('\\xa3','a')\n",
    "            if '\\xa4' in text: text = text.replace('\\xa4','a')\n",
    "            if '\\xe3' in text: text = text.replace('\\xe3','a')\n",
    "            if '\\xe0' in text: text = text.replace('\\xe0','a')\n",
    "\n",
    "            if '\\x82' in text: text = text.replace('\\x82','a')\n",
    "            if '\\x83' in text: text = text.replace('\\x83','a')\n",
    "            if '\\x81' in text: text = text.replace('\\x81','a')\n",
    "            if '\\x80' in text: text = text.replace('\\x80','a')\n",
    "\n",
    "            if '\\xa9' in text: text = text.replace('\\xa9','e')\n",
    "            if '\\xaa' in text: text = text.replace('\\xaa','e')\n",
    "\n",
    "            if '\\x89' in text: text = text.replace('\\x89','e')\n",
    "            if '\\x8a' in text: text = text.replace('\\x8a','e')\n",
    "            if '\\x8e' in text: text = text.replace('\\x8e','e')\n",
    "\n",
    "            if '\\xad' in text: text = text.replace('\\xad','i')\n",
    "\n",
    "            if '\\x8d' in text: text = text.replace('\\x8d','i')\n",
    "            if '\\xcd' in text: text = text.replace('\\xcd','i')\n",
    "\n",
    "            if '\\xb3' in text: text = text.replace('\\xb3','o')\n",
    "            if '\\xb4' in text: text = text.replace('\\xb4','o')\n",
    "            if '\\xb5' in text: text = text.replace('\\xb5','o')\n",
    "            if '\\xd5' in text: text = text.replace('\\xd5','o')\n",
    "            if '\\xc5' in text: text = text.replace('\\xc5','o')\n",
    "\n",
    "            if '\\x93' in text: text = text.replace('\\x93','o')\n",
    "            if '\\x94' in text: text = text.replace('\\x94','o')\n",
    "            if '\\x95' in text: text = text.replace('\\x95','o')\n",
    "\n",
    "            if '\\xba' in text: text = text.replace('\\xba','u')\n",
    "            if '\\xda' in text: text = text.replace('\\xda','u')\n",
    "            if '\\xbc' in text: text = text.replace('\\xbc','u')\n",
    "            if '\\xfc' in text: text = text.replace('\\xfc','u')\n",
    "\n",
    "            if '\\x9a' in text: text = text.replace('\\x9a','u')\n",
    "            if '\\x9c' in text: text = text.replace('\\x9c','u')\n",
    "            if '\\xfa' in text: text = text.replace('\\xfa','u')\n",
    "\n",
    "            if '\\xa7' in text: text = text.replace('\\xa7','c')\n",
    "            if '\\x87' in text: text = text.replace('\\x87','c')\n",
    "            if '\\xe7' in text: text = text.replace('\\xe7','c')\n",
    "            if '\\x8d' in text: text = text.replace('\\x8d','c')\n",
    "            if '\\xc7' in text: text = text.replace('\\xc7','c')\n",
    "\n",
    "            if '\\xf4' in text: text = text.replace('\\xf4','o')\n",
    "            if '\\xe2' in text: text = text.replace('\\xe2','a')\n",
    "            if '\\xb0' in text: text = text.replace('\\xb0','o')\n",
    "            if '\\xb2' in text: text = text.replace('\\xb2','q')\n",
    "            if '\\xc9' in text: text = text.replace('\\xc9','e')\n",
    "            if '\\xd3' in text: text = text.replace('\\xd3','o')\n",
    "            if '\\xeb' in text: text = text.replace('\\xeb','e')\n",
    "            if '\\xc8' in text: text = text.replace('\\xc8','e')\n",
    "            if '\\xf1' in text: text = text.replace('\\xf1','n')\n",
    "            if '\\xc2' in text: text = text.replace('\\xc2','a')\n",
    "            if '\\xc0' in text: text = text.replace('\\xc0','a')\n",
    "            if '\\xdf' in text: text = text.replace('\\xdf','s')\n",
    "            if '\\xae' in text: text = text.replace('\\xae','i')\n",
    "            if '\\xb7' in text: text = text.replace('\\xb7','-')\n",
    "            if '\\xf9' in text: text = text.replace('\\xf9','u')\n",
    "            if '\\xac' in text: text = text.replace('\\xac','o')\n",
    "            if '\\xf2' in text: text = text.replace('\\xf2','o')\n",
    "            if '\\xd6' in text: text = text.replace('\\xd6','-')\n",
    "            if '\\xb9' in text: text = text.replace('\\xb9','-')\n",
    "\n",
    "            if '\\xf8' in text: text = text.replace('\\xf8','o')\n",
    "            if '\\xce' in text: text = text.replace('\\xce','i')\n",
    "            if '\\xdc' in text: text = text.replace('\\xdc','u')\n",
    "            if '\\xa8' in text: text = text.replace('\\xa8','-')\n",
    "            if '\\x8b' in text: text = text.replace('\\x8b','a')\n",
    "            if '\\x99' in text: text = text.replace('\\x99','o')\n",
    "            if '\\x9f' in text: text = text.replace('\\x9f','u')\n",
    "            if '\\xe5' in text: text = text.replace('\\xe5','a')\n",
    "            if '\\x9b' in text: text = text.replace('\\x9b','o')\n",
    "            if '\\xe6' in text: text = text.replace('\\xe6','e')\n",
    "            if '\\xcc' in text: text = text.replace('\\xcc','a')\n",
    "            if '\\x91' in text: text = text.replace('\\x91','e')\n",
    "\n",
    "            if '\\xef' in text: text = text.replace('\\xef','o')\n",
    "            if '\\x96' in text: text = text.replace('\\x96','n')\n",
    "            if '\\xcb' in text: text = text.replace('\\xcb','a')\n",
    "            if '\\x8f' in text: text = text.replace('\\x8f','e')\n",
    "            if '\\xbb' in text: text = text.replace('\\xbb','-')\n",
    "            if '\\x9d' in text: text = text.replace('\\x9d','u')\n",
    "            if '\\xd2' in text: text = text.replace('\\xd2','-')\n",
    "            if '\\xab' in text: text = text.replace('\\xab','-')\n",
    "            if '\\xbf' in text: text = text.replace('\\xbf','o')\n",
    "            if '\\xd0' in text: text = text.replace('\\xd0','-')\n",
    "            if '\\xdb' in text: text = text.replace('\\xdb','S')\n",
    "            if '\\xd1' in text: text = text.replace('\\xd1','-')\n",
    "            if '\\xfb' in text: text = text.replace('\\xfb','O')\n",
    "            if '\\xc6' in text: text = text.replace('\\xc6','a')\n",
    "            if '\\xb6' in text: text = text.replace('\\xb6','a')\n",
    "            if '\\x85' in text: text = text.replace('\\x85','a')\n",
    "\n",
    "        try:\n",
    "            str(text)\n",
    "        except:\n",
    "            print(text)\n",
    "        return str(text)\n",
    "\n",
    "\n",
    "    def replace_list(l):\n",
    "        s=[]\n",
    "        for x in l:\n",
    "            s.append(replace_str(x))\n",
    "        return s\n",
    "\n",
    "    def replace_df(df):\n",
    "        for column in df.columns:\n",
    "            df[column] = replace_list(df[column])\n",
    "        col = df.columns\n",
    "        col = replace_list(col)\n",
    "        df.columns = col\n",
    "        return df\n",
    "\n",
    "    if type(element) is str: #or type(element) is unicode: \n",
    "        element = replace_str(element)\n",
    "    elif type(element) is list or 'pandas.core.series.Series' in str(type(element)):\n",
    "        element = replace_list(element)\n",
    "    elif 'pandas.core.frame.DataFrame' in  str(type(element)):\n",
    "        element = replace_df(element)\n",
    "    else: \n",
    "        print('Please use string, unicode, list or pandas Dataframe')\n",
    "\n",
    "    return element\n",
    "\n",
    "def get_age_from_birth(col,reference_year=None,fixYear=False):\n",
    "    \"\"\"\n",
    "    Get age based on the information about birth date.\n",
    "    \n",
    "    Args:\n",
    "        col (Pandas Series'): pandas series containing the birth dates \n",
    "        reference_year (Int): Year to calculate the birth date if not using current\n",
    "        fix_year (Boolean): Fix if year is not in correct format or raise error instead\n",
    "    Returns:\n",
    "        l (list): list with the calculated ages\n",
    "    \"\"\"\n",
    "    \n",
    "\tl=[]\n",
    "\tfor year in col:\n",
    "\t\tif fixYear:\n",
    "\t\t\tyear = fix_year(year)\n",
    "\t\tyear = dt.datetime.strptime(year,'%m/%d/%Y')\n",
    "\t\tyear = year.year\n",
    "\t\tif reference_year is None:\n",
    "\t\t\tage = dt.datetime.now().year-year\n",
    "\t\telse:\n",
    "\t\t\tage = reference_year-year\n",
    "\t\tl.append(age)\n",
    "\treturn l\n",
    "\n",
    "def fix_year(string_date):\n",
    "\ttry:\n",
    "\t\tif string_date is not None:\n",
    "\t\t\ts=string_date\n",
    "\t\t\tidx = find_all_ch('/',s)\n",
    "\t\t\tif int(s[idx[-1]+1:])>17:\n",
    "\t\t\t\ty= '19' + s[idx[-1]+1:]\n",
    "\t\t\telse:\n",
    "\t\t\t\ty= '20' + s[idx[-1]+1:]\n",
    "\t\t\ts=s[:idx[-1]+1] + y\n",
    "\t\t\treturn s\n",
    "\t\treturn None\n",
    "\texcept Exception as e:\n",
    "\t\treturn '01/01/2000'\n",
    "    \n",
    "def get_stds(col,label = ['very below','below','mean','above','very above']):\n",
    "\tsm=col.mean()\n",
    "\tst=col.std()\n",
    "\tstds = [sm-2*st,sm-st,sm+st,sm+2*st]\n",
    "\tl=[]\n",
    "\tfor v in col:\n",
    "\t\tif v<stds[0]: l.append(label[0])\n",
    "\t\telif v<stds[1]: l.append(label[1])\n",
    "\t\telif v<stds[2]: l.append(label[2])\n",
    "\t\telif v<stds[3]: l.append(label[3])\n",
    "\t\telse: l.append(label[4])\n",
    "\treturn l\n",
    "\n",
    "band_dict = {\n",
    "\t\t\t 'ceo':0.0, 'ebm':0.0,\n",
    "\t\t\t '0-a':0.0,'0-b':0.5,\n",
    "\t\t\t 'i-a':1.0,'i-b':1.5,\n",
    "\t\t\t 'ii-a':2.0,'ii-b':2.5,\n",
    "\t\t\t 'iii-a':3.0,'iii-b':3.5,\n",
    "\t\t\t 'iv-a':4.0,'iv-b':4.5,\n",
    "\t\t\t 'v-a':5.0,'v-b':5.5,\n",
    "\t\t\t 'vi-a':6.0,'vi-b':6.5,\n",
    "\t\t\t 'vii-a':7.0,'vii-b':7.5,\n",
    "\t\t\t 'viii-a':8.0,'viii-b':8.5,\n",
    "\t\t\t 'ix-a':9.0,'ix-b':9.5,\n",
    "\t\t\t 'x-a':10.0,'x-b':10.5,\n",
    "\t\t\t 'xi-a':11.0,'xi-b':11.5,\n",
    "\t\t\t \n",
    "\t\t\t 'cra-t1':12.0,'cra-t2':12.0,'cra-t3':12.0,\n",
    "\t\t\t 'crb-t1':12.0,'crb-t2':12.0,'crb-t3':12.0,'cr-b':12.0,\n",
    "\t\t\t 'crc-t1':12.0,'crc-t2':12.0,'crc-t3':12.0,'crc-t4':12.0,\n",
    "\t\t\t 'crd-t1':12.0,'crd-t2':12.0,'crd-t3':12.0,'crd-t4':12.0,\n",
    "\t\t\t 'cre':12.0,'cre-t1':12.0,'cre-t2':12.0,'cre-t3':12.0,\n",
    "\t\t\t 'crf-t1':12.0,'crf-t2':12.0,'crf-t3':12.0,'crf-t4':12.0,\n",
    "\t\t\t 'crg-t1':12.0,'crg-t2':12.0,'crg-t3':12.0,\n",
    "\t\t\t 'cr-a':12.0, 'cr-c':12.0, 'cr-d':12.0, 'cr-e':12.0, 'cr-f':12.0,\n",
    "\t\t\t 'cr-g':12.0, 'crc':12.0, 'crf':12.0, 'crg':12.0,\n",
    "\t\t\t \n",
    "\t\t\t 'usd2':12.0,'usd4':12.0,\n",
    "\t\t\t \n",
    "\t\t\t 'qct-1':12.0,'qct-2':12.0,'qct-3':12.0,'qct-4':12.0,\n",
    "\t\t\t 'qct-c':12.0,'qct-d':12.0,'qct-i':12.0,'qct-ii':12.0,\n",
    "\t\t\t 'qgr-ii':12.0,'qgr-iii':12.0,\n",
    "\t\t\t \n",
    "\t\t\t 'cont':12.0,\n",
    "\t\t\t 'advsr':12.0,\n",
    "\t\t\t \n",
    "\t\t\t 'qppt':12.0,\n",
    "\t\t\t 'qrep':12.0,\n",
    "\t\t\t 'hourly':12.0,\n",
    "\t\t\t}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T06:31:29.778135Z",
     "start_time": "2020-07-13T06:31:29.770014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mendes/Box Sync/ABI-Project/Project/NAZ/People/TurnoverModel/Data/Working/2015/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T05:20:44.654063Z",
     "start_time": "2020-07-13T05:20:44.644294Z"
    }
   },
   "outputs": [],
   "source": [
    "#read turnover information from 2014\n",
    "tk14 = pd.read_csv(adlsopen(path_working+'tk14.csv'),dtype='str')\n",
    "#define the keys for turnover in 2014\n",
    "tk14 = set(tk14['id'])\n",
    "\n",
    "#read turnover information from 2015\n",
    "tk15 = pd.read_csv(adlsopen(path_working+'tk15.csv'),dtype='str')\n",
    "#define the keys for turnover in 2015\n",
    "tk15 = set(tk15['id'])\n",
    "\n",
    "#read turnover information from 2016\n",
    "tk16 = pd.read_csv(adlsopen(path_working+'tk16.csv'),dtype='str')\n",
    "#define the keys for turnover in 2016\n",
    "tk16 = set(tk16['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder SharpOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headcount\n",
    "\n",
    "This is the general information about the employees. This dataset can also be called the demographic information about the employees. Here we collect information such as name, global id, age, and location of work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T05:20:44.819466Z",
     "start_time": "2020-07-13T05:20:44.688862Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#read headcount information for 2014\n",
    "h14 = pd.read_csv(adlsopen(path_head+'Headcount_2014_Year_End.csv'),low_memory=False,encoding='latin')\n",
    "\n",
    "#convert the id to the standard format applied to all ids\n",
    "h14['Global ID'] = convert_id(h14['Global ID'])\n",
    "\n",
    "#get the set that contains all ids\n",
    "hk14 = set(h14['Global ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build dataset for headcount 14 with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T05:20:49.260786Z",
     "start_time": "2020-07-13T05:20:44.821391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    18424\n",
      "Name: label, dtype: int64\n",
      "0    1.0\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#get the ids for the people who were not in the company in 2014\n",
    "idx14=list(hk14.intersection(tk15))\n",
    "\n",
    "#use procedure to process raw dataset\n",
    "h14 = headcount_procedure(h14,idx14)\n",
    "\n",
    "#print information about the distribuitions of the labels in the dataset\n",
    "print(h14['label'].value_counts())\n",
    "print(h14['label'].value_counts()/len(h14))\n",
    "\n",
    "#create a version with the simple name columns\n",
    "h14_raw = h14.copy(deep=True)\n",
    "\n",
    "#add information about the dataset in the name of the column in order to identify the source\n",
    "h14.columns = ['head --- '+k if k!= 'global id' and k!='label' else k for k in h14.columns ]\n",
    "\n",
    "#save the dataset created\n",
    "save_csv_adls(replace_special(h14.drop(['head --- personnel number manager'],axis=1)),\n",
    "              path_to_save+'head14.csv',adls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (venv-abi-py3)",
   "language": "python",
   "name": "venv-abi-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
